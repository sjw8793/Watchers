{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'updated_seoul_flood_data.csv'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드\n",
    "flood_data = pd.read_excel('seoul_flood_data_with_drainage.xlsx')\n",
    "rain_data = pd.read_csv('서울시날씨데이터.csv')\n",
    "\n",
    "# 각 형식에 맞게 변환하기 위한 함수 정의\n",
    "def parse_dates(date_str, time_str):\n",
    "    if len(time_str) <= 2:\n",
    "        combined = date_str + ' ' + time_str.zfill(2) + '00'\n",
    "    else:\n",
    "        combined = date_str + ' ' + time_str\n",
    "    \n",
    "    try:\n",
    "        return pd.to_datetime(combined, format='%Y-%m-%d %H%M')\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return pd.to_datetime(combined, format='%Y%m%d %H%M')\n",
    "        except ValueError:\n",
    "            return pd.NaT\n",
    "\n",
    "# '침수 시작 시간' 열에 변환된 datetime 값 할당\n",
    "flood_data['침수 시작 시간'] = flood_data.apply(lambda row: parse_dates(str(row['침수 시작 날짜']), str(row['침수 시작 시간'])), axis=1)\n",
    "\n",
    "# 강수 데이터의 날짜를 datetime으로 변환\n",
    "rain_data['일시'] = pd.to_datetime(rain_data['일시'])\n",
    "\n",
    "# 계산할 시간 범위 설정 (1시간부터 12시간까지)\n",
    "time_ranges = range(1, 13)\n",
    "\n",
    "# 각 구별로 강수량 계산 및 데이터 추가\n",
    "for index, row in flood_data.iterrows():\n",
    "    district = row['GU_NAM']\n",
    "    flood_start = row['침수 시작 시간']\n",
    "    extended_flood_time = flood_start + pd.Timedelta(hours=24)  # 침수 시작 시간에 3시간을 더함\n",
    "    \n",
    "    # 해당 구의 데이터만 필터링\n",
    "    district_rain_data = rain_data[rain_data['지점'] == district]\n",
    "    \n",
    "    # 침수 시작 시간 ~ 3시간 이후까지의 데이터를 필터링\n",
    "    filtered_data = district_rain_data[district_rain_data['일시'] <= extended_flood_time].sort_values(by='일시', ascending=False)\n",
    "    \n",
    "    for hours in time_ranges:\n",
    "        # 특정 시간 범위의 데이터 필터링\n",
    "        time_window = filtered_data[(filtered_data['일시'] > extended_flood_time - pd.Timedelta(hours=hours)) & (filtered_data['일시'] <= extended_flood_time)]\n",
    "        \n",
    "        if not time_window.empty:\n",
    "            total_rainfall = time_window['강수량(mm)'].sum()\n",
    "            avg_rainfall_per_10min = total_rainfall / (hours * 6)  # 1시간 = 60분, 10분 단위이므로 시간당 6개의 데이터가 존재함\n",
    "            hourly_rainfall = time_window['강수량(mm)'].mean()\n",
    "            \n",
    "            # 결과를 데이터프레임에 추가\n",
    "            flood_data.loc[index, f'{hours}시간 누적 강수량(mm)'] = total_rainfall\n",
    "            flood_data.loc[index, f'{hours}시간 10분 평균 강수량(mm)'] = avg_rainfall_per_10min\n",
    "            flood_data.loc[index, f'{hours}시간 시간당 강수량(mm)'] = hourly_rainfall\n",
    "        else:\n",
    "            # 데이터가 부족할 경우 NaN으로 채움\n",
    "            flood_data.loc[index, f'{hours}시간 누적 강수량(mm)'] = np.nan\n",
    "            flood_data.loc[index, f'{hours}시간 10분 평균 강수량(mm)'] = np.nan\n",
    "            flood_data.loc[index, f'{hours}시간 시간당 강수량(mm)'] = np.nan\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "output_csv_path = 'updated_seoul_flood_data.csv'\n",
    "flood_data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# CSV 파일 경로를 사용자에게 전달\n",
    "output_csv_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'updated_seoul_flood_data2.csv'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 강수량 관련 칼럼들\n",
    "rainfall_columns = [\n",
    "    f'{hours}시간 누적 강수량(mm)' for hours in time_ranges\n",
    "] + [\n",
    "    f'{hours}시간 10분 평균 강수량(mm)' for hours in time_ranges\n",
    "] + [\n",
    "    f'{hours}시간 시간당 강수량(mm)' for hours in time_ranges\n",
    "]\n",
    "\n",
    "# 전부 NaN이거나 비어있거나 0인 행 제거\n",
    "flood_data = flood_data.dropna(subset=rainfall_columns, how='all')  # NaN인 행 제거\n",
    "flood_data = flood_data[~(flood_data[rainfall_columns] == 0).all(axis=1)]  # 0인 행 제거\n",
    "flood_data = flood_data[~(flood_data[rainfall_columns] == '').all(axis=1)]  # 비어있는 행 제거\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "output_csv_path = 'updated_seoul_flood_data2.csv'\n",
    "flood_data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# CSV 파일 경로를 사용자에게 전달\n",
    "output_csv_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'updated_seoul_flood_data.csv'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 특정 강수량 관련 칼럼들\n",
    "rainfall_columns = [\n",
    "    '1시간 누적 강수량(mm)', '1시간 10분 평균 강수량(mm)', '1시간 시간당 강수량(mm)',\n",
    "    '2시간 누적 강수량(mm)', '2시간 10분 평균 강수량(mm)', '2시간 시간당 강수량(mm)',\n",
    "    '3시간 누적 강수량(mm)', '3시간 10분 평균 강수량(mm)', '3시간 시간당 강수량(mm)',\n",
    "    '4시간 누적 강수량(mm)', '4시간 10분 평균 강수량(mm)', '4시간 시간당 강수량(mm)'\n",
    "]\n",
    "\n",
    "# 모든 값이 NaN이거나 비어있거나 0인 행 제거\n",
    "condition = (flood_data[rainfall_columns].isna().all(axis=1)) | (flood_data[rainfall_columns] == 0).all(axis=1) | (flood_data[rainfall_columns] == '').all(axis=1)\n",
    "flood_data = flood_data[~condition]\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "output_csv_path = 'updated_seoul_flood_data.csv'\n",
    "flood_data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# CSV 파일 경로를 사용자에게 전달\n",
    "output_csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'updated_seoul_flood_data3.csv'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 데이터 로드\n",
    "flood_data = pd.read_csv('침수학습데이터.csv')\n",
    "rain_data = pd.read_csv('서울시날씨데이터.csv')\n",
    "\n",
    "# '일시' 열을 datetime 형식으로 변환\n",
    "rain_data['일시'] = pd.to_datetime(rain_data['일시'])\n",
    "\n",
    "# 기존의 침수 일자 리스트 생성\n",
    "existing_flood_dates = flood_data['침수 시작 날짜'].unique()\n",
    "\n",
    "# 랜덤 날짜/시간 생성 함수 정의 (2022년 중, 기존의 침수 일자와 겹치지 않도록)\n",
    "def generate_random_datetime_in_2022(exclude_dates):\n",
    "    start_date = datetime(2022, 1, 1)\n",
    "    end_date = datetime(2022, 12, 31, 23, 59)\n",
    "    while True:\n",
    "        random_date = start_date + timedelta(seconds=random.randint(0, int((end_date - start_date).total_seconds())))\n",
    "        if random_date.date() not in exclude_dates:\n",
    "            return random_date\n",
    "\n",
    "# 필요한 컬럼을 유지하면서 새로운 데이터 생성\n",
    "new_data = flood_data[['centroid_lon', 'centroid_lat', 'GU_NAM', '배수정보', '침수된 지역의 평균 지형 고도']].copy()\n",
    "\n",
    "# 랜덤 날짜와 시간을 생성하여 데이터프레임에 추가\n",
    "new_data['침수 시작 날짜'] = new_data.apply(lambda _: generate_random_datetime_in_2022(existing_flood_dates).date(), axis=1)\n",
    "new_data['침수 시작 시간'] = new_data.apply(lambda row: generate_random_datetime_in_2022(existing_flood_dates).time(), axis=1)\n",
    "\n",
    "# '침수 시작 시간' 열을 datetime으로 변환\n",
    "new_data['침수 시작 시간'] = pd.to_datetime(new_data['침수 시작 날짜'].astype(str) + ' ' + new_data['침수 시작 시간'].astype(str))\n",
    "\n",
    "# 계산할 시간 범위 설정 (1시간부터 12시간까지)\n",
    "time_ranges = range(1, 13)\n",
    "\n",
    "# 각 구별로 강수량 계산 및 데이터 추가\n",
    "for index, row in new_data.iterrows():\n",
    "    district = row['GU_NAM']\n",
    "    flood_start = row['침수 시작 시간']\n",
    "    \n",
    "    # 해당 구의 데이터만 필터링\n",
    "    district_rain_data = rain_data[rain_data['지점'] == district]\n",
    "    \n",
    "    # 침수 시작 시간 이후의 데이터를 필터링\n",
    "    filtered_data = district_rain_data[district_rain_data['일시'] >= flood_start].sort_values(by='일시', ascending=True)\n",
    "    \n",
    "    for hours in time_ranges:\n",
    "        # 특정 시간 범위의 데이터 필터링\n",
    "        time_window = filtered_data[(filtered_data['일시'] < flood_start + pd.Timedelta(hours=hours))]\n",
    "        \n",
    "        if not time_window.empty:\n",
    "            total_rainfall = time_window['강수량(mm)'].sum()\n",
    "            avg_rainfall_per_10min = total_rainfall / (hours * 6)  # 1시간 = 60분, 10분 단위이므로 시간당 6개의 데이터가 존재함\n",
    "            hourly_rainfall = time_window['강수량(mm)'].mean()\n",
    "            \n",
    "            # 결과를 데이터프레임에 추가\n",
    "            new_data.loc[index, f'{hours}시간 누적 강수량(mm)'] = total_rainfall\n",
    "            new_data.loc[index, f'{hours}시간 10분 평균 강수량(mm)'] = avg_rainfall_per_10min\n",
    "            new_data.loc[index, f'{hours}시간 시간당 강수량(mm)'] = hourly_rainfall\n",
    "        else:\n",
    "            # 데이터가 부족할 경우 NaN으로 채움\n",
    "            new_data.loc[index, f'{hours}시간 누적 강수량(mm)'] = np.nan\n",
    "            new_data.loc[index, f'{hours}시간 10분 평균 강수량(mm)'] = np.nan\n",
    "            new_data.loc[index, f'{hours}시간 시간당 강수량(mm)'] = np.nan\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "output_csv_path = 'updated_seoul_flood_data3.csv'\n",
    "new_data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# CSV 파일 경로를 사용자에게 전달\n",
    "output_csv_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'updated_seoul_flood_data4.csv'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특정 강수량 관련 칼럼들\n",
    "rainfall_columns = [\n",
    "    '1시간 누적 강수량(mm)', '1시간 10분 평균 강수량(mm)', '1시간 시간당 강수량(mm)',\n",
    "    '2시간 누적 강수량(mm)', '2시간 10분 평균 강수량(mm)', '2시간 시간당 강수량(mm)',\n",
    "    '3시간 누적 강수량(mm)', '3시간 10분 평균 강수량(mm)', '3시간 시간당 강수량(mm)',\n",
    "    '4시간 누적 강수량(mm)', '4시간 10분 평균 강수량(mm)', '4시간 시간당 강수량(mm)'\n",
    "]\n",
    "\n",
    "# 모든 값이 NaN이거나 비어있거나 0인 행 제거\n",
    "condition = (new_data[rainfall_columns].isna().all(axis=1)) | (new_data[rainfall_columns] == '').all(axis=1)\n",
    "new_data = new_data[~condition]\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "output_csv_path = 'updated_seoul_flood_data4.csv'\n",
    "new_data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# CSV 파일 경로를 사용자에게 전달\n",
    "output_csv_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
